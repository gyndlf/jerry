{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d6623, d6897\n",
    "# Generate a model that classifies card values, from the images created\n",
    "# Uses images in suits/train and suits/test (but test is not added yet)\n",
    "# Heavily \"inspired\" by catsvdogs model from keras\n",
    "\n",
    "# Flow\n",
    "# 1. Load all the data\n",
    "# 2. Train on model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_dir = '/Users/James/Projects/PycharmProjects/jerry/cards'\n",
    "train_dir = os.path.join(base_dir, 'value/train')\n",
    "val_dir = os.path.join(base_dir, 'value/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making training generator\n",
      "Found 91 images belonging to 13 classes.\n",
      "Making validation generator\n",
      "Found 13 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "def value_to_label(val):\n",
    "    # Cause its really weird the order goes backwards\n",
    "    # 10, 11, 12, 13, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
    "    labels = [1, 10, 11, 12, 13, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    return labels[val]\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,  # Just to add some more datapoints\n",
    "                                   brightness_range=[0.2, 2],\n",
    "                                   shear_range=3.0,\n",
    "                                   zoom_range=[.95, 1.05],\n",
    "                                   rotation_range=5,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "#val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# Replaced since it can flow from same directory\n",
    "\n",
    "batch_size = 5\n",
    "print(\"Making training generator\")\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                        target_size=(150,150),\n",
    "                                        batch_size=batch_size,\n",
    "                                        color_mode='grayscale',\n",
    "                                        class_mode='categorical',\n",
    "                                        subset='training',\n",
    "                                        shuffle=True)\n",
    "\n",
    "print(\"Making validation generator\")\n",
    "val_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                target_size=(150, 150),\n",
    "                                                batch_size=batch_size,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='categorical',\n",
    "                                                subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some example data\n",
    "img = plt.imread(os.path.join(train_dir, \"1/club_0.jpg\"))\n",
    "plt.imshow(img)\n",
    "\n",
    "img = np.expand_dims(img, axis=0)\n",
    "ex_datagen = train_datagen\n",
    "ex_datagen.fit(img)\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "it = ex_datagen.flow(img)\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(it.next().reshape(288,352, 3))  # Lol that reshape was a total guess\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "length = 104  # how far to cycle to see every image\n",
    "print('\\nSample of example input train image')\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    plt.matshow(inputs_batch[0].reshape(150,150))\n",
    "    plt.show()\n",
    "\n",
    "    print('label of', value_to_label(labels_batch[0].argmax(axis=0)))\n",
    "    print('Shape of', inputs_batch.shape)\n",
    "    break\n",
    "\n",
    "print('\\nSample of example input validation image')\n",
    "for inputs_batch, labels_batch in val_generator:\n",
    "    print(inputs_batch[0].shape)\n",
    "    plt.matshow(inputs_batch[0].reshape(150,150))\n",
    "    plt.show()\n",
    "\n",
    "    print('label of', value_to_label(labels_batch[0].argmax(axis=0)))\n",
    "    print('Shape of', inputs_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               6554112   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                3341      \n",
      "=================================================================\n",
      "Total params: 6,800,205\n",
      "Trainable params: 6,800,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, optimizers\n",
    "from keras import models\n",
    "\n",
    "# Probably too complex for this situiation, but I don't care\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu', input_shape=(150,150,1)))\n",
    "model.add(layers.MaxPooling2D((3,3)))  # Make the view larger; find bigger patterns\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())  # Dimension reduce\n",
    "model.add(layers.Dropout(0.5))  # Get rid of conspiracies\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(13, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch', epoch)\n",
    "\n",
    "\n",
    "from time import time\n",
    "start = time()\n",
    "history = model.fit(train_generator,\n",
    "                  steps_per_epoch=train_generator.samples // batch_size,  # 10 * 10 = 100 from 104 samples\n",
    "                  epochs=500,\n",
    "                  validation_data=val_generator,\n",
    "                  validation_steps=val_generator.samples // batch_size,\n",
    "                  verbose=0,\n",
    "                  callbacks=[CustomCallback()])  # total of 128*100=12800 samples used\n",
    "print('Took',(time()-start).__round__(4),'seconds to train the network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    }
   ],
   "source": [
    "save = False\n",
    "load = True\n",
    "export = False\n",
    "\n",
    "if save:\n",
    "    # save the model\n",
    "    print('Saving model...')\n",
    "    model.save('models/value-v4.h5')\n",
    "    print('Saved.')\n",
    "\n",
    "if load:\n",
    "    # Load it\n",
    "    print('Loading model...')\n",
    "    model = models.load_model(os.path.join(base_dir, 'models/value-v4.h5'))\n",
    "\n",
    "if export:\n",
    "    print('Exporting model...')\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    with open('models/value-v4.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualise the training data\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "val_acc = history.history['val_acc']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()  # Combines the two graphs\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on all cards\n",
      "Testing num 9\n",
      "8 / 8\n",
      "Testing num 11\n",
      "8 / 8\n",
      "Testing num 7\n",
      "8 / 8\n",
      "Testing num 6\n",
      "8 / 8\n",
      "Testing num 1\n",
      "8 / 8\n",
      "Testing num 10\n",
      "6 / 8\n",
      "Testing num 8\n",
      "8 / 8\n",
      "Testing num 4\n",
      "8 / 8\n",
      "Testing num 3\n",
      "8 / 8\n",
      "Testing num 12\n",
      "8 / 8\n",
      "Testing num 2\n",
      "8 / 8\n",
      "Testing num 13\n",
      "8 / 8\n",
      "Testing num 5\n",
      "8 / 8\n",
      "Overall accuracy of 98.08 %\n",
      "(102/104)\n"
     ]
    }
   ],
   "source": [
    "# Test on custom image\n",
    "from keras.preprocessing import image\n",
    "\n",
    "print('Testing on all cards')\n",
    "\n",
    "overall = [0,0]\n",
    "\n",
    "for num in os.listdir(train_dir):\n",
    "    if num != '.DS_Store':\n",
    "        print('Testing num', num)\n",
    "\n",
    "        dir = os.path.join(train_dir, num)\n",
    "\n",
    "        fnames = []\n",
    "        for fname in os.listdir(dir):\n",
    "            if fname != '.DS_Store':\n",
    "                fnames.append(os.path.join(dir, fname))\n",
    "\n",
    "        overall[1] += fnames.__len__()\n",
    "        correct = 0\n",
    "\n",
    "        for img_path in fnames:\n",
    "            img = image.load_img(img_path,\n",
    "                                 target_size=(150,150),\n",
    "                                 color_mode='grayscale')\n",
    "\n",
    "            x = image.img_to_array(img)\n",
    "            x = x.astype('float32')/255\n",
    "            x = x.reshape((1,) + x.shape)  # Convert from (150,150,1) to (1,150,150,1)\n",
    "\n",
    "            pred = model.predict(x, verbose=0)\n",
    "            pred = pred.reshape(13)\n",
    "\n",
    "            #print(\"\\nPrediction of\", value_to_label(pred.argmax(axis=0)))\n",
    "            #print(\"With certainty of\", pred[pred.argmax(axis=0)].__round__(2))\n",
    "\n",
    "            if value_to_label(pred.argmax(axis=0)) == int(num):\n",
    "                correct += 1\n",
    "        print(correct, '/', fnames.__len__())\n",
    "        overall[0] += correct\n",
    "print('Overall accuracy of', (overall[0]/overall[1]*100).__round__(2),'%')\n",
    "print('(%s/%s)' % (overall[0], overall[1]))\n",
    "\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}